I currently know about some introductory content on search algorithms in artificial intelligence.
I currently know about some introductory content on search algorithms in artificial intelligence.
I currently know about some introductory content on search algorithms in artificial intelligence.
I currently know about some introductory content on search algorithms in artificial intelligence.
I currently know about some introductory content on search algorithms in artificial intelligence.
A* Search combines the cost to reach to the node, g(n), with the cost of going from the node to the goal, h(n), i.e., f(n) = g(n) + h(n). f(n) is the cost of the best known path from the start node to a goal node that passes through n. It is equivalent to Uniform-Cost Search except that A* uses g+h instead of g.
A* Search combines the cost to reach to the node, g(n), with the cost of going from the node to the goal, h(n), i.e., f(n) = g(n) + h(n). f(n) is the cost of the best known path from the start node to a goal node that passes through n. It is equivalent to Uniform-Cost Search except that A* uses g+h instead of g.
A* Search combines the cost to reach to the node, g(n), with the cost of going from the node to the goal, h(n), i.e., f(n) = g(n) + h(n). f(n) is the cost of the best known path from the start node to a goal node that passes through n. It is equivalent to Uniform-Cost Search except that A* uses g+h instead of g.
A* Search combines the cost to reach to the node, g(n), with the cost of going from the node to the goal, h(n), i.e., f(n) = g(n) + h(n). f(n) is the cost of the best known path from the start node to a goal node that passes through n. It is equivalent to Uniform-Cost Search except that A* uses g+h instead of g.
A* Search combines the cost to reach to the node, g(n), with the cost of going from the node to the goal, h(n), i.e., f(n) = g(n) + h(n). f(n) is the cost of the best known path from the start node to a goal node that passes through n. It is equivalent to Uniform-Cost Search except that A* uses g+h instead of g.
A* proof: We say that the path P is optimal, if there is no other path Q, from n0 to nk, such that Pcost(Q) < Pcost(P). We note that if P is optimal, and x and y are nodes on P, then subPath(P,x,y) is also optimal – if there were a less costly path from x to y, substitute that path in P, to get a less costly path than P. If we say that a path to a node x is optimal, we mean that the path from the start node, s, to x is optimal. | Proof of Optimality: We prove that A* for graph-search is optimal given that h is consistent by the following steps. We show: 1. h(x) ≤ Pcost(P) + h(y) whenever P is a path from x to y. 2. When a node is selected and removed from the frontier, the path to that node in the search graph is optimal. 3. Nodes are removed from the frontier in non- decreasing order by f.
A* proof: We say that the path P is optimal, if there is no other path Q, from n0 to nk, such that Pcost(Q) < Pcost(P). We note that if P is optimal, and x and y are nodes on P, then subPath(P,x,y) is also optimal – if there were a less costly path from x to y, substitute that path in P, to get a less costly path than P. If we say that a path to a node x is optimal, we mean that the path from the start node, s, to x is optimal. | Proof of Optimality: We prove that A* for graph-search is optimal given that h is consistent by the following steps. We show: 1. h(x) ≤ Pcost(P) + h(y) whenever P is a path from x to y. 2. When a node is selected and removed from the frontier, the path to that node in the search graph is optimal. 3. Nodes are removed from the frontier in non- decreasing order by f.
A* proof: We say that the path P is optimal, if there is no other path Q, from n0 to nk, such that Pcost(Q) < Pcost(P). We note that if P is optimal, and x and y are nodes on P, then subPath(P,x,y) is also optimal – if there were a less costly path from x to y, substitute that path in P, to get a less costly path than P. If we say that a path to a node x is optimal, we mean that the path from the start node, s, to x is optimal. | Proof of Optimality: We prove that A* for graph-search is optimal given that h is consistent by the following steps. We show: 1. h(x) ≤ Pcost(P) + h(y) whenever P is a path from x to y. 2. When a node is selected and removed from the frontier, the path to that node in the search graph is optimal. 3. Nodes are removed from the frontier in non- decreasing order by f.
General Tree Search Algorithm, Breadth-first search, Uniform-cost search, Depth-first search, Depth-limited search, Iterative deepening search
General Tree Search Algorithm: function Tree-Search(problem) returns a solution or failure initialize the frontier using the initial state of problem {loop do {if the frontier is empty then return failure} {choose a leaf node and remove it from the frontier if the node contains a goal state then return the expand the chosen node, adding the resulting nodes to the corresponding solution frontier}
General Tree Search Algorithm: function Tree-Search(problem) returns a solution or failure initialize the frontier using the initial state of problem {loop do {if the frontier is empty then return failure} {choose a leaf node and remove it from the frontier if the node contains a goal state then return the expand the chosen node, adding the resulting nodes to the corresponding solution frontier}
General Tree Search Algorithm: function Tree-Search(problem) returns a solution or failure initialize the frontier using the initial state of problem {loop do {if the frontier is empty then return failure} {choose a leaf node and remove it from the frontier if the node contains a goal state then return the expand the chosen node, adding the resulting nodes to the corresponding solution frontier}
General Tree Search Algorithm: function Tree-Search(problem) returns a solution or failure initialize the frontier using the initial state of problem {loop do {if the frontier is empty then return failure} {choose a leaf node and remove it from the frontier if the node contains a goal state then return the expand the chosen node, adding the resulting nodes to the corresponding solution frontier}
General Tree Search Algorithm: function Tree-Search(problem) returns a solution or failure initialize the frontier using the initial state of problem {loop do {if the frontier is empty then return failure} {choose a leaf node and remove it from the frontier if the node contains a goal state then return the expand the chosen node, adding the resulting nodes to the corresponding solution frontier}
General Tree Search Algorithm: function Tree-Search(problem) returns a solution or failure initialize the frontier using the initial state of problem {loop do {if the frontier is empty then return failure} {choose a leaf node and remove it from the frontier if the node contains a goal state then return the expand the chosen node, adding the resulting nodes to the corresponding solution frontier}
Breadth-First Search: Expand the root node, then the children of the root node, then the children of the children of the root node, and so on. All nodes at a given depth (length of the sequence of actions to create that node) are expanded before any nodes at a greater depth are expanded. Implementation: Use a (FIFO) queue to implement the frontier. New nodes go to the back of the queue, thus the oldest nodes (created first) are expanded first. Complete? Yes (if b, the branching factor, is finite) Time? 1+b+b2+b3+... +bd + b(bd-1) = O(bd+1). Space? O(bd+1) (keeps every node in memory). Optimal? Yes (if cost = 1 per step). Space is the bigger problem (more than time)
Breadth-First Search: Expand the root node, then the children of the root node, then the children of the children of the root node, and so on. All nodes at a given depth (length of the sequence of actions to create that node) are expanded before any nodes at a greater depth are expanded. Implementation: Use a (FIFO) queue to implement the frontier. New nodes go to the back of the queue, thus the oldest nodes (created first) are expanded first. Complete? Yes (if b, the branching factor, is finite) Time? 1+b+b2+b3+... +bd + b(bd-1) = O(bd+1). Space? O(bd+1) (keeps every node in memory). Optimal? Yes (if cost = 1 per step). Space is the bigger problem (more than time)
Breadth-First Search: Expand the root node, then the children of the root node, then the children of the children of the root node, and so on. All nodes at a given depth (length of the sequence of actions to create that node) are expanded before any nodes at a greater depth are expanded. Implementation: Use a (FIFO) queue to implement the frontier. New nodes go to the back of the queue, thus the oldest nodes (created first) are expanded first. Complete? Yes (if b, the branching factor, is finite) Time? 1+b+b2+b3+... +bd + b(bd-1) = O(bd+1). Space? O(bd+1) (keeps every node in memory). Optimal? Yes (if cost = 1 per step). Space is the bigger problem (more than time)
Breadth-First Search: Expand the root node, then the children of the root node, then the children of the children of the root node, and so on. All nodes at a given depth (length of the sequence of actions to create that node) are expanded before any nodes at a greater depth are expanded. Implementation: Use a (FIFO) queue to implement the frontier. New nodes go to the back of the queue, thus the oldest nodes (created first) are expanded first. Complete? Yes (if b, the branching factor, is finite) Time? 1+b+b2+b3+... +bd + b(bd-1) = O(bd+1). Space? O(bd+1) (keeps every node in memory). Optimal? Yes (if cost = 1 per step). Space is the bigger problem (more than time)
Breadth-First Search: Expand the root node, then the children of the root node, then the children of the children of the root node, and so on. All nodes at a given depth (length of the sequence of actions to create that node) are expanded before any nodes at a greater depth are expanded. Implementation: Use a (FIFO) queue to implement the frontier. New nodes go to the back of the queue, thus the oldest nodes (created first) are expanded first. Complete? Yes (if b, the branching factor, is finite) Time? 1+b+b2+b3+... +bd + b(bd-1) = O(bd+1). Space? O(bd+1) (keeps every node in memory). Optimal? Yes (if cost = 1 per step). Space is the bigger problem (more than time)
Breadth-First Search: Expand the root node, then the children of the root node, then the children of the children of the root node, and so on. All nodes at a given depth (length of the sequence of actions to create that node) are expanded before any nodes at a greater depth are expanded. Implementation: Use a (FIFO) queue to implement the frontier. New nodes go to the back of the queue, thus the oldest nodes (created first) are expanded first. Complete? Yes (if b, the branching factor, is finite) Time? 1+b+b2+b3+... +bd + b(bd-1) = O(bd+1). Space? O(bd+1) (keeps every node in memory). Optimal? Yes (if cost = 1 per step). Space is the bigger problem (more than time)
Breadth-First Search: Expand the root node, then the children of the root node, then the children of the children of the root node, and so on. All nodes at a given depth (length of the sequence of actions to create that node) are expanded before any nodes at a greater depth are expanded. Implementation: Use a (FIFO) queue to implement the frontier. New nodes go to the back of the queue, thus the oldest nodes (created first) are expanded first. Complete? Yes (if b, the branching factor, is finite) Time? 1+b+b2+b3+... +bd + b(bd-1) = O(bd+1). Space? O(bd+1) (keeps every node in memory). Optimal? Yes (if cost = 1 per step). Space is the bigger problem (more than time)
Breadth-First Search: Expand the root node, then the children of the root node, then the children of the children of the root node, and so on. All nodes at a given depth (length of the sequence of actions to create that node) are expanded before any nodes at a greater depth are expanded. Implementation: Use a (FIFO) queue to implement the frontier. New nodes go to the back of the queue, thus the oldest nodes (created first) are expanded first. Complete? Yes (if b, the branching factor, is finite) Time? 1+b+b2+b3+... +bd + b(bd-1) = O(bd+1). Space? O(bd+1) (keeps every node in memory). Optimal? Yes (if cost = 1 per step). Space is the bigger problem (more than time)
Uniform-Cost Search: Instead of expanding the shallowest node, uniform-cost search expands the node, n, with the lowest Path-Cost, g(n). Implementation: Use a min priority queue to implement the frontier. The priority is g(n). There are two other differences from breadth-first search: 1. The goal test is applied when a node is selected for expansion, rather than when it is generated. 2. A test is added to check whether a better path has been found to a node on the frontier. Equivalent to breadth-first if step costs all equal. Complete? Yes, if step cost ≥ ε, where ε is a small, positive constant. Time? # of nodes with g ≤ cost of optimal solution, where C* is the cost of the optimal solution. Space? # of nodes with g ≤ cost of optimal solution. Optimal? Yes – nodes expanded in increasing order of g(n).
Uniform-Cost Search: Instead of expanding the shallowest node, uniform-cost search expands the node, n, with the lowest Path-Cost, g(n). Implementation: Use a min priority queue to implement the frontier. The priority is g(n). There are two other differences from breadth-first search: 1. The goal test is applied when a node is selected for expansion, rather than when it is generated. 2. A test is added to check whether a better path has been found to a node on the frontier. Equivalent to breadth-first if step costs all equal. Complete? Yes, if step cost ≥ ε, where ε is a small, positive constant. Time? # of nodes with g ≤ cost of optimal solution, where C* is the cost of the optimal solution. Space? # of nodes with g ≤ cost of optimal solution. Optimal? Yes – nodes expanded in increasing order of g(n).
Uniform-Cost Search: Instead of expanding the shallowest node, uniform-cost search expands the node, n, with the lowest Path-Cost, g(n). Implementation: Use a min priority queue to implement the frontier. The priority is g(n). There are two other differences from breadth-first search: 1. The goal test is applied when a node is selected for expansion, rather than when it is generated. 2. A test is added to check whether a better path has been found to a node on the frontier. Equivalent to breadth-first if step costs all equal. Complete? Yes, if step cost ≥ ε, where ε is a small, positive constant. Time? # of nodes with g ≤ cost of optimal solution, where C* is the cost of the optimal solution. Space? # of nodes with g ≤ cost of optimal solution. Optimal? Yes – nodes expanded in increasing order of g(n).
Uniform-Cost Search: Instead of expanding the shallowest node, uniform-cost search expands the node, n, with the lowest Path-Cost, g(n). Implementation: Use a min priority queue to implement the frontier. The priority is g(n). There are two other differences from breadth-first search: 1. The goal test is applied when a node is selected for expansion, rather than when it is generated. 2. A test is added to check whether a better path has been found to a node on the frontier. Equivalent to breadth-first if step costs all equal. Complete? Yes, if step cost ≥ ε, where ε is a small, positive constant. Time? # of nodes with g ≤ cost of optimal solution, where C* is the cost of the optimal solution. Space? # of nodes with g ≤ cost of optimal solution. Optimal? Yes – nodes expanded in increasing order of g(n).
Uniform-Cost Search: Instead of expanding the shallowest node, uniform-cost search expands the node, n, with the lowest Path-Cost, g(n). Implementation: Use a min priority queue to implement the frontier. The priority is g(n). There are two other differences from breadth-first search: 1. The goal test is applied when a node is selected for expansion, rather than when it is generated. 2. A test is added to check whether a better path has been found to a node on the frontier. Equivalent to breadth-first if step costs all equal. Complete? Yes, if step cost ≥ ε, where ε is a small, positive constant. Time? # of nodes with g ≤ cost of optimal solution, where C* is the cost of the optimal solution. Space? # of nodes with g ≤ cost of optimal solution. Optimal? Yes – nodes expanded in increasing order of g(n).
Uniform-Cost Search: Instead of expanding the shallowest node, uniform-cost search expands the node, n, with the lowest Path-Cost, g(n). Implementation: Use a min priority queue to implement the frontier. The priority is g(n). There are two other differences from breadth-first search: 1. The goal test is applied when a node is selected for expansion, rather than when it is generated. 2. A test is added to check whether a better path has been found to a node on the frontier. Equivalent to breadth-first if step costs all equal. Complete? Yes, if step cost ≥ ε, where ε is a small, positive constant. Time? # of nodes with g ≤ cost of optimal solution, where C* is the cost of the optimal solution. Space? # of nodes with g ≤ cost of optimal solution. Optimal? Yes – nodes expanded in increasing order of g(n).
Uniform-Cost Search: Instead of expanding the shallowest node, uniform-cost search expands the node, n, with the lowest Path-Cost, g(n). Implementation: Use a min priority queue to implement the frontier. The priority is g(n). There are two other differences from breadth-first search: 1. The goal test is applied when a node is selected for expansion, rather than when it is generated. 2. A test is added to check whether a better path has been found to a node on the frontier. Equivalent to breadth-first if step costs all equal. Complete? Yes, if step cost ≥ ε, where ε is a small, positive constant. Time? # of nodes with g ≤ cost of optimal solution, where C* is the cost of the optimal solution. Space? # of nodes with g ≤ cost of optimal solution. Optimal? Yes – nodes expanded in increasing order of g(n).
Depth-First Search always expands the deepest node in the current frontier. The search proceeds immediately to the deepest level of the search tree, where the nodes have no successors. As those nodes are expanded they are dropped from the frontier. Then search then “backs up” to the next deepest node that still has unexplored successors. Implementation: Use a stack to implement the frontier, or use recursion, and avoid using an explicit stack. Complete? No: fails in infinite-depth spaces, spaces with loops. However, DFS can be modified to avoid repeated states along path (just keep track of the states on the path) in order to assure completeness in finite spaces. Time? O(bm), where m is the length of the longest branch: terrible if m is much larger than d but if solutions are dense, may be much faster than breadth-first. Space? O(bm), i.e., linear space! Optimal? No
Depth-First Search always expands the deepest node in the current frontier. The search proceeds immediately to the deepest level of the search tree, where the nodes have no successors. As those nodes are expanded they are dropped from the frontier. Then search then “backs up” to the next deepest node that still has unexplored successors. Implementation: Use a stack to implement the frontier, or use recursion, and avoid using an explicit stack. Complete? No: fails in infinite-depth spaces, spaces with loops. However, DFS can be modified to avoid repeated states along path (just keep track of the states on the path) in order to assure completeness in finite spaces. Time? O(bm), where m is the length of the longest branch: terrible if m is much larger than d but if solutions are dense, may be much faster than breadth-first. Space? O(bm), i.e., linear space! Optimal? No
Depth-First Search always expands the deepest node in the current frontier. The search proceeds immediately to the deepest level of the search tree, where the nodes have no successors. As those nodes are expanded they are dropped from the frontier. Then search then “backs up” to the next deepest node that still has unexplored successors. Implementation: Use a stack to implement the frontier, or use recursion, and avoid using an explicit stack. Complete? No: fails in infinite-depth spaces, spaces with loops. However, DFS can be modified to avoid repeated states along path (just keep track of the states on the path) in order to assure completeness in finite spaces. Time? O(bm), where m is the length of the longest branch: terrible if m is much larger than d but if solutions are dense, may be much faster than breadth-first. Space? O(bm), i.e., linear space! Optimal? No
Depth-First Search always expands the deepest node in the current frontier. The search proceeds immediately to the deepest level of the search tree, where the nodes have no successors. As those nodes are expanded they are dropped from the frontier. Then search then “backs up” to the next deepest node that still has unexplored successors. Implementation: Use a stack to implement the frontier, or use recursion, and avoid using an explicit stack. Complete? No: fails in infinite-depth spaces, spaces with loops. However, DFS can be modified to avoid repeated states along path (just keep track of the states on the path) in order to assure completeness in finite spaces. Time? O(bm), where m is the length of the longest branch: terrible if m is much larger than d but if solutions are dense, may be much faster than breadth-first. Space? O(bm), i.e., linear space! Optimal? No
Depth-First Search always expands the deepest node in the current frontier. The search proceeds immediately to the deepest level of the search tree, where the nodes have no successors. As those nodes are expanded they are dropped from the frontier. Then search then “backs up” to the next deepest node that still has unexplored successors. Implementation: Use a stack to implement the frontier, or use recursion, and avoid using an explicit stack. Complete? No: fails in infinite-depth spaces, spaces with loops. However, DFS can be modified to avoid repeated states along path (just keep track of the states on the path) in order to assure completeness in finite spaces. Time? O(bm), where m is the length of the longest branch: terrible if m is much larger than d but if solutions are dense, may be much faster than breadth-first. Space? O(bm), i.e., linear space! Optimal? No
Depth-First Search always expands the deepest node in the current frontier. The search proceeds immediately to the deepest level of the search tree, where the nodes have no successors. As those nodes are expanded they are dropped from the frontier. Then search then “backs up” to the next deepest node that still has unexplored successors. Implementation: Use a stack to implement the frontier, or use recursion, and avoid using an explicit stack. Complete? No: fails in infinite-depth spaces, spaces with loops. However, DFS can be modified to avoid repeated states along path (just keep track of the states on the path) in order to assure completeness in finite spaces. Time? O(bm), where m is the length of the longest branch: terrible if m is much larger than d but if solutions are dense, may be much faster than breadth-first. Space? O(bm), i.e., linear space! Optimal? No
Depth-First Search always expands the deepest node in the current frontier. The search proceeds immediately to the deepest level of the search tree, where the nodes have no successors. As those nodes are expanded they are dropped from the frontier. Then search then “backs up” to the next deepest node that still has unexplored successors. Implementation: Use a stack to implement the frontier, or use recursion, and avoid using an explicit stack. Complete? No: fails in infinite-depth spaces, spaces with loops. However, DFS can be modified to avoid repeated states along path (just keep track of the states on the path) in order to assure completeness in finite spaces. Time? O(bm), where m is the length of the longest branch: terrible if m is much larger than d but if solutions are dense, may be much faster than breadth-first. Space? O(bm), i.e., linear space! Optimal? No
Depth-Limited Search is similar to Depth-First Search, but with a cutoff, limit. When depth limit is reached, the search is cut off, i.e., nodes at that depth are treated as having no children. The algorithm will note when cutoff, as opposed to outright failure, occurs. The algorithm is implemented very easily using recursion. The implicit control stack (storing the recursive function calls) is used instead of an explicit stack. Complete? Yes. Time? (d+1)b0 + d b1 + (d-1)b2 + ... + bd = O(bd) u  Space? O(bd). Optimal? Yes, if step cost = 1.
Depth-Limited Search is similar to Depth-First Search, but with a cutoff, limit. When depth limit is reached, the search is cut off, i.e., nodes at that depth are treated as having no children. The algorithm will note when cutoff, as opposed to outright failure, occurs. The algorithm is implemented very easily using recursion. The implicit control stack (storing the recursive function calls) is used instead of an explicit stack. Complete? Yes. Time? (d+1)b0 + d b1 + (d-1)b2 + ... + bd = O(bd) u  Space? O(bd). Optimal? Yes, if step cost = 1.
Depth-Limited Search is similar to Depth-First Search, but with a cutoff, limit. When depth limit is reached, the search is cut off, i.e., nodes at that depth are treated as having no children. The algorithm will note when cutoff, as opposed to outright failure, occurs. The algorithm is implemented very easily using recursion. The implicit control stack (storing the recursive function calls) is used instead of an explicit stack. Complete? Yes. Time? (d+1)b0 + d b1 + (d-1)b2 + ... + bd = O(bd) u  Space? O(bd). Optimal? Yes, if step cost = 1.
Depth-Limited Search is similar to Depth-First Search, but with a cutoff, limit. When depth limit is reached, the search is cut off, i.e., nodes at that depth are treated as having no children. The algorithm will note when cutoff, as opposed to outright failure, occurs. The algorithm is implemented very easily using recursion. The implicit control stack (storing the recursive function calls) is used instead of an explicit stack. Complete? Yes. Time? (d+1)b0 + d b1 + (d-1)b2 + ... + bd = O(bd) u  Space? O(bd). Optimal? Yes, if step cost = 1.
Depth-Limited Search is similar to Depth-First Search, but with a cutoff, limit. When depth limit is reached, the search is cut off, i.e., nodes at that depth are treated as having no children. The algorithm will note when cutoff, as opposed to outright failure, occurs. The algorithm is implemented very easily using recursion. The implicit control stack (storing the recursive function calls) is used instead of an explicit stack. Complete? Yes. Time? (d+1)b0 + d b1 + (d-1)b2 + ... + bd = O(bd) u  Space? O(bd). Optimal? Yes, if step cost = 1.
Depth-Limited Search is similar to Depth-First Search, but with a cutoff, limit. When depth limit is reached, the search is cut off, i.e., nodes at that depth are treated as having no children. The algorithm will note when cutoff, as opposed to outright failure, occurs. The algorithm is implemented very easily using recursion. The implicit control stack (storing the recursive function calls) is used instead of an explicit stack. Complete? Yes. Time? (d+1)b0 + d b1 + (d-1)b2 + ... + bd = O(bd) u  Space? O(bd). Optimal? Yes, if step cost = 1.
Depth-Limited Search is similar to Depth-First Search, but with a cutoff, limit. When depth limit is reached, the search is cut off, i.e., nodes at that depth are treated as having no children. The algorithm will note when cutoff, as opposed to outright failure, occurs. The algorithm is implemented very easily using recursion. The implicit control stack (storing the recursive function calls) is used instead of an explicit stack. Complete? Yes. Time? (d+1)b0 + d b1 + (d-1)b2 + ... + bd = O(bd) u  Space? O(bd). Optimal? Yes, if step cost = 1.
Iterative Deepening DFS: Do Depth-Limited Search with an increasing depth limit, i.e., set the limit to 0, then 1, then 2, ..., until a goal is reached. function Iterative-Deepening-Search(problem) returns a solution, or failure. Iterative Deepening does do extra work, because each time the depth bound is increased, the previous search tree is thrown away, and the new search redoes all the work in generating it (and then goes to another level). However, given a branching factor b, the next level as approximate b times as many nodes as the previous tree, thus extra work is not excessive. In general, iterative deepening is the preferred uninformed search method when the search space is large and the depth of the solution is not known. Complete? Yes. Time? (d+1)b0 + d b1 + (d-1)b2 + ... + bd = O(bd) u  Space? O(bd). Optimal? Yes, if step cost = 1.
Iterative Deepening DFS: Do Depth-Limited Search with an increasing depth limit, i.e., set the limit to 0, then 1, then 2, ..., until a goal is reached. function Iterative-Deepening-Search(problem) returns a solution, or failure. Iterative Deepening does do extra work, because each time the depth bound is increased, the previous search tree is thrown away, and the new search redoes all the work in generating it (and then goes to another level). However, given a branching factor b, the next level as approximate b times as many nodes as the previous tree, thus extra work is not excessive. In general, iterative deepening is the preferred uninformed search method when the search space is large and the depth of the solution is not known. Complete? Yes. Time? (d+1)b0 + d b1 + (d-1)b2 + ... + bd = O(bd) u  Space? O(bd). Optimal? Yes, if step cost = 1.
Iterative Deepening DFS: Do Depth-Limited Search with an increasing depth limit, i.e., set the limit to 0, then 1, then 2, ..., until a goal is reached. function Iterative-Deepening-Search(problem) returns a solution, or failure. Iterative Deepening does do extra work, because each time the depth bound is increased, the previous search tree is thrown away, and the new search redoes all the work in generating it (and then goes to another level). However, given a branching factor b, the next level as approximate b times as many nodes as the previous tree, thus extra work is not excessive. In general, iterative deepening is the preferred uninformed search method when the search space is large and the depth of the solution is not known. Complete? Yes. Time? (d+1)b0 + d b1 + (d-1)b2 + ... + bd = O(bd) u  Space? O(bd). Optimal? Yes, if step cost = 1.
Iterative Deepening DFS: Do Depth-Limited Search with an increasing depth limit, i.e., set the limit to 0, then 1, then 2, ..., until a goal is reached. function Iterative-Deepening-Search(problem) returns a solution, or failure. Iterative Deepening does do extra work, because each time the depth bound is increased, the previous search tree is thrown away, and the new search redoes all the work in generating it (and then goes to another level). However, given a branching factor b, the next level as approximate b times as many nodes as the previous tree, thus extra work is not excessive. In general, iterative deepening is the preferred uninformed search method when the search space is large and the depth of the solution is not known. Complete? Yes. Time? (d+1)b0 + d b1 + (d-1)b2 + ... + bd = O(bd) u  Space? O(bd). Optimal? Yes, if step cost = 1.
Iterative Deepening DFS: Do Depth-Limited Search with an increasing depth limit, i.e., set the limit to 0, then 1, then 2, ..., until a goal is reached. function Iterative-Deepening-Search(problem) returns a solution, or failure. Iterative Deepening does do extra work, because each time the depth bound is increased, the previous search tree is thrown away, and the new search redoes all the work in generating it (and then goes to another level). However, given a branching factor b, the next level as approximate b times as many nodes as the previous tree, thus extra work is not excessive. In general, iterative deepening is the preferred uninformed search method when the search space is large and the depth of the solution is not known. Complete? Yes. Time? (d+1)b0 + d b1 + (d-1)b2 + ... + bd = O(bd) u  Space? O(bd). Optimal? Yes, if step cost = 1.
Iterative Deepening DFS: Do Depth-Limited Search with an increasing depth limit, i.e., set the limit to 0, then 1, then 2, ..., until a goal is reached. function Iterative-Deepening-Search(problem) returns a solution, or failure. Iterative Deepening does do extra work, because each time the depth bound is increased, the previous search tree is thrown away, and the new search redoes all the work in generating it (and then goes to another level). However, given a branching factor b, the next level as approximate b times as many nodes as the previous tree, thus extra work is not excessive. In general, iterative deepening is the preferred uninformed search method when the search space is large and the depth of the solution is not known. Complete? Yes. Time? (d+1)b0 + d b1 + (d-1)b2 + ... + bd = O(bd) u  Space? O(bd). Optimal? Yes, if step cost = 1.
Iterative Deepening DFS: Do Depth-Limited Search with an increasing depth limit, i.e., set the limit to 0, then 1, then 2, ..., until a goal is reached. function Iterative-Deepening-Search(problem) returns a solution, or failure. Iterative Deepening does do extra work, because each time the depth bound is increased, the previous search tree is thrown away, and the new search redoes all the work in generating it (and then goes to another level). However, given a branching factor b, the next level as approximate b times as many nodes as the previous tree, thus extra work is not excessive. In general, iterative deepening is the preferred uninformed search method when the search space is large and the depth of the solution is not known. Complete? Yes. Time? (d+1)b0 + d b1 + (d-1)b2 + ... + bd = O(bd) u  Space? O(bd). Optimal? Yes, if step cost = 1.
I am implementing a natural language processor for taking in input, hand coded decision trees for quick responses, and neural nets for picking the correct response from my knowledge base. Right now my implementations are simple. . . Simply AWESOME!
I am implementing a natural language processor for taking in input, hand coded decision trees for quick responses, and neural nets for picking the correct response from my knowledge base. Right now my implementations are simple. . . Simply AWESOME!
I am implementing a natural language processor for taking in input, hand coded decision trees for quick responses, and neural nets for picking the correct response from my knowledge base. Right now my implementations are simple. . . Simply AWESOME!
Informed (Heuristic) Search: The search strategies we've discussed so far are all general strategies. Informed, or heuristic, search uses problem-specific knowledge to guide the search process in the hopes of finding a goal state more quickly. These strategies are a form of priority-first search where a priority queue is used to implement the frontier. An evaluation function, f(n), is used as the priority of node n.
Informed (Heuristic) Search: The search strategies we've discussed so far are all general strategies. Informed, or heuristic, search uses problem-specific knowledge to guide the search process in the hopes of finding a goal state more quickly. These strategies are a form of priority-first search where a priority queue is used to implement the frontier. An evaluation function, f(n), is used as the priority of node n.
Heuristics are: Rules of thumbs, Educated guesses, Ways to use outside knowledge when searching Rules for a simplified (relaxed) version of the problem, or Rules derived by studying subproblems Rules learned from experience.
Heuristics are: Rules of thumbs, Educated guesses, Ways to use outside knowledge when searching Rules for a simplified (relaxed) version of the problem, or Rules derived by studying subproblems Rules learned from experience.
Relaxed Problems: These heuristics are exact measures for variants of the 8- puzzle. If the rules were changed so that a tile could move anywhere instead of to an adjacent empty square, then h1 would give the exact number of steps in the solution. Similarly, if a tile could move one square in any direction, even if there's already a tile there, then h2 would give the right number. A simplification of the original is called a relaxed problem. In general, relaxed problems can be used to generate
heuristics.
Pattern Databases: Solutions to subproblems can be used to generate heuristics. For example, in the 8-puzzle, a sub- problem could be to get tiles 1, 2, 3, and 4 in their proper places. The cost of solving the subproblem is a lower bound on the cost of solving the whole problem. A pattern database would store the exact solution costs for every subproblem. When a subproblem occurs, look it up, and use that value as h.
Tentative Schedule: Date Topic(s) Readings: 1. 1/11 Introduction, Search Chap. 1-3 | 1/18 MLK Day – No Class | 2. 1/25 Informed Search Chap. 4,5 | 3. 2/1 CSP, Logical Agents Chap. 6,7 | 4. 2/8 First-Order Logic Chap. 8 | 5. 2/15 Automated Reasoning | Chap. 9, Prover9 home page, Prover9 manual Prover9 examples, Prolog Manual | 6. 2/22 Mid-term; Planning Chap. 10, 11 | 2/29 Spring Break: No class | 7. 3/7 Knowledge Representation Chap. 12 | 8. 3/14 Uncertain Knowledge & Reasoning Chap. 13, 14 | 9. 3/21 Learning from Examples Chap. 18 | 3/28 Easter Break – No Class | 10. 3/30 Knowledge in Learning, Reinforcement Chap. 19, 21 (Wed.) | 11. 4/4 Natural Language Processing Chap. 22 | 12. 4/11 More NLP Chap. 23 | 13. 4/18 Perception Chap. 24 | 14. | 4/25 Project Presentations | 5/2 Final – 6:00 pm to 8:00 pm
Students with documented disabilities are entitled to reasonable accommodations if needed. If you need accommodations, please contact the Office of Freshman Development and Special Student Services in 309 Duquesne University (412-397-6657) as soon as possible. Accommodations will not be granted retrospectively.
A homework or program assignment will lose 5 points per day that it is late. Weekends are counted as one day. Homework assignments and programs may not be turned in after they are discussed in class. All programs and homework must be turned in by 4/26/16. Work turned in after that time will not be accepted.
A project addressing a problem in artificial intelligence is required. The project should be the equivalent of three weeks of homework in terms of effort. The topic is of the student's own choosing, with the consent of the professor. The project should involve programming, mathematical analysis, and/or statistical analysis in a significant way. If the program contains code, source code must be included with the project. A write-up of 5-10 pages is also required. Examples of projects are: An expert system for tree identification, a spam filter, a chess program, a sudoku solver, a simple, domain specific question and answering system, or a neural net to solve a classification problem. The project could solve a problem in a new way, or could be an implementation of a known approach to a new problem.
Dr. Simon is the professor of the class and here is his contact information: Office Hours: MWF 1:00 PM - 3:00 PM, M 5:00 PM - 6:00 PM, or by Appointment. E-mail: simond@duq.edu Home Page: www.mathcs.duq.edu/profs/simon.html Office / Phone: 416 College Hall / 396-6472
Dr. Simon is the professor of the class and here is his contact information: Office Hours: MWF 1:00 PM - 3:00 PM, M 5:00 PM - 6:00 PM, or by Appointment. E-mail: simond@duq.edu Home Page: www.mathcs.duq.edu/profs/simon.html Office / Phone: 416 College Hall / 396-6472
Dr. Simon is the professor of the class and here is his contact information: Office Hours: MWF 1:00 PM - 3:00 PM, M 5:00 PM - 6:00 PM, or by Appointment. E-mail: simond@duq.edu Home Page: www.mathcs.duq.edu/profs/simon.html Office / Phone: 416 College Hall / 396-6472
Dr. Simon is the professor of the class and here is his contact information: Office Hours: MWF 1:00 PM - 3:00 PM, M 5:00 PM - 6:00 PM, or by Appointment. E-mail: simond@duq.edu Home Page: www.mathcs.duq.edu/profs/simon.html Office / Phone: 416 College Hall / 396-6472
Grading: Assignments & Programs 40% Project 15% Mid-term 20% Final 30%. Assignments and programs are due at class time. Tests are in-class and closed book. Grading Scale: 100-90 = A, 89-80 = B, 79-70 = C, 69-60 = D, below 60 = F. Plus-minus grading will not be used. Honor Policy: Students in this class fall under the mandate of the University's academic integrity policy. Any student guilty of plagiarism will receive a grade of 'F' for the course and will be repor Work done in this course is to be by the individual, not a group. You may not share (copy, give, show) your homework with other students in the course Any code not your own that is included in your programs must be properly cited. This includes code from the book and that given by the professor. Submitted work must be your own work, although you may include code from the book (or book's website) and that given out by the instruction. If the code is not your own, it must be properly attributed.
Four Philosophies of artificial intelligence: Thinking Humanly, Thinking Rationally, Acting Humanly, and Acting Rationally
Four Philosophies of artificial intelligence: Thinking Humanly, Thinking Rationally, Acting Humanly, and Acting Rationally
Four Philosophies of artificial intelligence: Thinking Humanly, Thinking Rationally, Acting Humanly, and Acting Rationally
Thinking Humanly: Cognitive Modeling: Determine how humans think. Reproduce thought process in machines. Testable theories of how the mind works. Carbon-based vs. silicon-based processing. Examples: General Problem Solver (Newell & Simon), Neural Nets (McCulloch & Pitts), Transferring Consciousness (Moravec)
Acting Humanly: Simulation: Program need not simulate human thought, but rather human behavior. Perform tasks that require human intelligence: Natural language, Reasoning, Planning, Learning, Knowledge representation, Vision. Turing Test (Turing, 1950), Loebner Prize
Thinking Rationally: Logicist Approach: Logical, rigorous reasoning. Formal logic. Systematize all necessary knowledge. Inference is key. May out-perform humans.
Acting Rationally: Rational Agent Approach: Operate autonomously: Perceive environment, React to stimuli, Create and pursue goals, Adapt to change. Achieve the “best” outcome according to some external measure. Similar skills to acting humanly. Internal mechanism may differ from humans. This is the course Book's approach.
Specifying the Task Environment: PEAS: Performance measure, Environment, Actuators, Sensors. Must first specify the setting for intelligent agent design. Consider the task of designing an automated taxi driver:. Performance measure: Safe, fast, legal, comfortable trip, maximize profits. Environment: Roads, other traffic, pedestrians, customers. Actuators: Steering, accelerator, brake, signal, horn, display. Sensors: Cameras, radar, sonar, speedometer, GPS, odometer, accelerometer, engine sensors, keyboard
Specifying the Task Environment: PEAS: Performance measure, Environment, Actuators, Sensors. Must first specify the setting for intelligent agent design. Consider the task of designing an automated taxi driver:. Performance measure: Safe, fast, legal, comfortable trip, maximize profits. Environment: Roads, other traffic, pedestrians, customers. Actuators: Steering, accelerator, brake, signal, horn, display. Sensors: Cameras, radar, sonar, speedometer, GPS, odometer, accelerometer, engine sensors, keyboard
You guess is as good as mine.
I don’t know why you listen to a thing I say.